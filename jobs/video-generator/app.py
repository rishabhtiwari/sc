"""
Video Generation Job Service - Main Application
"""

import os
import sys
import time
from datetime import datetime

# Add common directory to path for job framework
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'common'))

from flask import send_file, jsonify
from common.models.base_job import BaseJob
from common.utils.logger import setup_logger
from config.settings import Config
from services.video_generation_service import VideoGenerationService
from services.video_merge_service import VideoMergeService


class VideoGeneratorJob(BaseJob):
    """Video Generation Job that extends BaseJob framework"""

    def __init__(self):
        super().__init__("video-generator", Config)
        self.video_service = VideoGenerationService(self.config, self.logger)
        self.merge_service = VideoMergeService(self.config, self.logger)

        # Initialize MongoDB connection
        from pymongo import MongoClient
        self.mongo_client = MongoClient(self.config.MONGODB_URI)

        # Connect to news database for reading articles
        self.news_client = MongoClient(self.config.NEWS_MONGODB_URL)
        self.news_db = self.news_client[self.config.NEWS_MONGODB_DATABASE]
        self.news_collection = self.news_db['news_document']

        # Validate configuration
        try:
            self.config.validate_config()
            self.logger.info("‚úÖ Configuration validation passed")
        except ValueError as e:
            self.logger.error(f"‚ùå Configuration validation failed: {str(e)}")
            raise

    def get_job_type(self) -> str:
        """Return the job type identifier"""
        return "video-generator"

    def get_service_info(self) -> dict:
        """Return service information"""
        return {
            'name': self.config.SERVICE_NAME,
            'version': self.config.SERVICE_VERSION,
            'description': self.config.SERVICE_DESCRIPTION,
            'job_type': self.get_job_type(),
            'status': 'running',
            'last_run': None,
            'config': {
                'interval_minutes': self.config.JOB_INTERVAL_MINUTES,
                'max_threads': self.config.MAX_THREADS,
                'video_quality': self.config.VIDEO_QUALITY,
                'video_dimensions': f"{self.config.VIDEO_WIDTH}x{self.config.VIDEO_HEIGHT}",
                'video_fps': self.config.VIDEO_FPS
            }
        }

    def run_job(self, job_id: str, is_on_demand: bool = False, **kwargs) -> dict:
        """
        Main job execution method - finds articles with audio but no video and generates videos
        """
        try:
            self.logger.info(f"üöÄ Starting video generation job {job_id} (on_demand: {is_on_demand})...")
            self.logger.info(f"üîç DEBUG: run_job called with job_id={job_id}, is_on_demand={is_on_demand}")

            # Get articles that need video generation
            articles_to_process = self._get_articles_for_video_generation()

            if not articles_to_process:
                self.logger.info("üì≠ No articles found that need video generation")
                result = {
                    'status': 'completed',  # Changed from 'success' to 'completed' for BaseJob framework
                    'message': 'No articles to process',
                    'processed_count': 0,
                    'success_count': 0,
                    'error_count': 0
                }
                self.logger.info(f"üîç DEBUG: Returning early result: {result}")
                return result

            self.logger.info(f"üìã Found {len(articles_to_process)} articles to process")

            # Store articles for parallel processing
            self.current_articles = articles_to_process

            # Process articles in parallel
            self.logger.info(f"üîç DEBUG: About to call run_parallel_tasks with job_id: {job_id}")
            results = self.run_parallel_tasks(job_id)

            self.logger.info(f"üîç DEBUG: Parallel tasks results structure: {type(results)}")
            self.logger.info(f"üîç DEBUG: Results keys: {results.keys() if isinstance(results, dict) else 'Not a dict'}")

            # Extract actual task results for database updates
            task_results = []
            if isinstance(results, dict) and 'task_details' in results:
                self.logger.info(f"üîç DEBUG: Found task_details with {len(results['task_details'])} tasks")
                for task_name, task_result in results['task_details'].items():
                    if task_result.get('status') == 'completed':
                        task_results.append(task_result.get('result', {}))
                        self.logger.info(f"üîç DEBUG: Added result for task {task_name}: {task_result.get('result', {})}")
                    else:
                        self.logger.warning(f"‚ö†Ô∏è DEBUG: Task {task_name} not completed: {task_result.get('status')}")
            else:
                self.logger.warning(f"‚ö†Ô∏è DEBUG: Unexpected results structure: {results}")

            self.logger.info(f"üîç DEBUG: Extracted {len(task_results)} task results for database update")

            # Update database with results
            self.logger.info(f"üîç DEBUG: About to call _update_database_with_results")
            success_count = self._update_database_with_results(task_results)
            self.logger.info(f"üîç DEBUG: _update_database_with_results returned: {success_count}")

            # Calculate statistics
            total_processed = len(task_results)
            error_count = total_processed - success_count

            self.logger.info(f"‚úÖ Video generation job completed")
            self.logger.info(f"üìä Processed: {total_processed}, Success: {success_count}, Errors: {error_count}")

            final_result = {
                'status': 'completed',  # Changed from 'success' to 'completed' for BaseJob framework
                'message': f'Video generation completed',
                'processed_count': total_processed,
                'success_count': success_count,
                'error_count': error_count,
                'timestamp': datetime.utcnow().isoformat()
            }

            self.logger.info(f"üîç DEBUG: Final result being returned from run_job: {final_result}")
            return final_result

        except Exception as e:
            error_msg = f"Video generation job failed: {str(e)}"
            self.logger.error(f"üí• {error_msg}")
            error_result = {
                'status': 'failed',  # Changed from 'error' to 'failed' for BaseJob framework
                'error': error_msg,
                'timestamp': datetime.utcnow().isoformat()
            }
            self.logger.info(f"üîç DEBUG: Error result being returned from run_job: {error_result}")
            return error_result

    def get_parallel_tasks(self) -> list:
        """
        Convert articles into parallel tasks for processing

        Returns:
            List of task dictionaries for parallel processing
        """
        articles = getattr(self, 'current_articles', [])
        tasks = []

        for article in articles:
            task = {
                'name': f"video_generation_{article['id']}",
                'function': self.process_single_task,
                'args': (article,),
                'kwargs': {}
            }
            tasks.append(task)

        return tasks

    def process_single_task(self, article: dict, job_id: str = None, **kwargs) -> dict:
        """
        Process a single video generation task

        Args:
            article: Article document from database
            job_id: Job ID passed by BaseJob framework
            **kwargs: Additional parameters from BaseJob framework

        Returns:
            Result dictionary with processing outcome
        """
        try:
            article_id = article['id']

            self.logger.info(f"üé¨ Processing video generation for article: {article_id}")

            # Generate video using the video service
            result = self.video_service.generate_video_for_article(article)

            if result['status'] == 'success':
                self.logger.info(f"‚úÖ Video generated successfully for article: {article_id}")
            else:
                self.logger.error(
                    f"‚ùå Video generation failed for article: {article_id} - {result.get('error', 'Unknown error')}")

            return result

        except Exception as e:
            error_msg = f"Error processing video generation task: {str(e)}"
            self.logger.error(f"üí• {error_msg}")
            return {
                'status': 'error',
                'error': error_msg,
                'article_id': article.get('id', 'unknown')
            }

    def _get_articles_for_video_generation(self) -> list:
        """
        Get articles that have audio but no video generated yet
        
        Returns:
            List of article documents that need video generation
        """
        try:
            # Query for articles that have audio_paths but no video_path
            query = {
                'audio_paths': {'$ne': None, '$exists': True},  # Has audio paths
                'video_path': {'$in': [None, '']},  # No video yet
                'image': {'$ne': None, '$exists': True},  # Has image URL
                'status': {'$in': ['completed', 'published']}  # Only process completed articles
            }

            # Get all articles that need video generation
            articles = list(
                self.news_collection.find(query)
                .sort('updated_at', -1)  # Process newest first
            )

            self.logger.info(f"üîç Found {len(articles)} articles ready for video generation")

            return articles

        except Exception as e:
            self.logger.error(f"Error querying articles for video generation: {str(e)}")
            return []

    def _update_database_with_results(self, results: list) -> int:
        """
        Update database with video generation results

        Args:
            results: List of processing results

        Returns:
            Number of successful updates
        """
        self.logger.info(f"üîç DEBUG: _update_database_with_results called with {len(results)} results")
        success_count = 0

        for i, result in enumerate(results):
            try:
                self.logger.info(f"üîç DEBUG: Processing result {i + 1}/{len(results)}: {result}")

                article_id = result.get('article_id')
                if not article_id:
                    self.logger.warning(f"‚ö†Ô∏è DEBUG: Result {i + 1} missing article_id: {result}")
                    continue

                self.logger.info(f"üîç DEBUG: Processing article_id: {article_id}, status: {result.get('status')}")

                if result['status'] == 'success':
                    # Update article with video path
                    update_data = {
                        'video_path': result['video_path'],
                        'updated_at': datetime.utcnow()
                    }

                    self.logger.info(f"üîç DEBUG: Base update_data for {article_id}: {update_data}")

                    # Add optional fields if available
                    if result.get('thumbnail_path'):
                        update_data['thumbnail_path'] = result['thumbnail_path']
                    if result.get('duration_seconds'):
                        update_data['video_duration_seconds'] = result['duration_seconds']
                    if result.get('file_size_mb'):
                        update_data['video_file_size_mb'] = result['file_size_mb']

                    self.logger.info(f"üîç DEBUG: Final update_data for {article_id}: {update_data}")

                    # Update the document
                    self.logger.info(f"üîç DEBUG: Executing MongoDB update for article: {article_id}")
                    update_result = self.news_collection.update_one(
                        {'id': article_id},
                        {'$set': update_data}
                    )

                    self.logger.info(
                        f"üîç DEBUG: MongoDB update result - matched: {update_result.matched_count}, modified: {update_result.modified_count}")

                    if update_result.modified_count > 0:
                        success_count += 1
                        self.logger.info(f"‚úÖ Updated database for article: {article_id}")
                    else:
                        self.logger.warning(f"‚ö†Ô∏è No document updated for article: {article_id}")
                else:
                    # Log error but don't update database for failed generations
                    self.logger.error(
                        f"‚ùå Video generation failed for article {article_id}: {result.get('error', 'Unknown error')}")

            except Exception as e:
                self.logger.error(
                    f"üí• Error updating database for article {result.get('article_id', 'unknown')}: {str(e)}")

        self.logger.info(f"üîç DEBUG: Database update completed. Success count: {success_count}")
        return success_count

    def _setup_routes(self):
        """Setup Flask routes including base routes and video merging routes"""
        # Call parent method to setup base routes
        super()._setup_routes()

        # Add video merging routes
        """Setup additional Flask routes for video merging"""

        @self.app.route('/merge-latest', methods=['POST'])
        def merge_latest_videos():
            """Merge latest 20 news videos into a single video"""
            try:
                self.logger.info("üé¨ Starting merge of latest 20 news videos")

                # Get latest news with videos
                latest_news = list(self.news_collection.find(
                    {"video_path": {"$exists": True, "$ne": None}},
                    {"id": 1, "title": 1, "video_path": 1, "created_at": 1}
                ).sort("created_at", -1).limit(20))

                if not latest_news:
                    return jsonify({
                        "error": "No news videos found",
                        "status": "error"
                    }), 404

                self.logger.info(f"üìä Found {len(latest_news)} news videos to merge")

                # Return immediate response to user with processing status
                from threading import Thread
                import time

                def merge_videos_async():
                    try:
                        self.logger.info("üé¨ Starting async video merge process...")
                        start_time = time.time()

                        # Merge videos
                        result = self.merge_service.merge_latest_videos(latest_news)

                        end_time = time.time()
                        processing_time = round(end_time - start_time, 2)

                        if result['status'] == 'success':
                            self.logger.info(
                                f"‚úÖ Video merge completed successfully in {processing_time} seconds - merged {result['video_count']} videos")
                        else:
                            self.logger.error(f"‚ùå Video merge failed: {result['error']}")

                    except Exception as e:
                        self.logger.error(f"‚ùå Error in async video merge: {str(e)}")

                # Start async processing
                thread = Thread(target=merge_videos_async)
                thread.daemon = True
                thread.start()

                return jsonify({
                    "message": f"Video merging started for {len(latest_news)} videos. This process may take 2-5 minutes depending on video length and quality.",
                    "status": "processing",
                    "video_count": len(latest_news),
                    "estimated_time": "2-5 minutes",
                    "download_url": "/download/latest-20-news.mp4",
                    "note": "Please wait for processing to complete before downloading. Check server logs for progress updates."
                })

            except Exception as e:
                self.logger.error(f"‚ùå Error starting video merge: {str(e)}")
                return jsonify({
                    "error": f"Failed to start video merge: {str(e)}",
                    "status": "error"
                }), 500

        @self.app.route('/merge-status', methods=['GET'])
        def get_merge_status():
            """Check the status of video merging process"""
            try:
                merged_video_path = os.path.join(self.config.VIDEO_OUTPUT_DIR, 'latest-20-news.mp4')

                if os.path.exists(merged_video_path):
                    # Get file info
                    file_stats = os.stat(merged_video_path)
                    file_size_mb = round(file_stats.st_size / (1024 * 1024), 2)
                    modified_time = time.ctime(file_stats.st_mtime)

                    return jsonify({
                        "status": "completed",
                        "message": "Merged video is ready for download",
                        "file_size_mb": file_size_mb,
                        "last_updated": modified_time,
                        "download_url": "/download/latest-20-news.mp4"
                    })
                else:
                    return jsonify({
                        "status": "not_found",
                        "message": "No merged video found. Please start the merge process first using /merge-latest endpoint."
                    })

            except Exception as e:
                self.logger.error(f"‚ùå Error checking merge status: {str(e)}")
                return jsonify({
                    "error": f"Failed to check status: {str(e)}",
                    "status": "error"
                }), 500

        @self.app.route('/download/latest-20-news.mp4', methods=['GET'])
        def download_merged_video():
            """Download the merged video file"""
            try:
                merged_video_path = os.path.join(self.config.VIDEO_OUTPUT_DIR, 'latest-20-news.mp4')

                if not os.path.exists(merged_video_path):
                    return jsonify({
                        "error": "Merged video not found. Please run /merge-latest first.",
                        "status": "error"
                    }), 404

                return send_file(
                    merged_video_path,
                    as_attachment=True,
                    download_name='latest-20-news.mp4',
                    mimetype='video/mp4'
                )

            except Exception as e:
                self.logger.error(f"‚ùå Error downloading merged video: {str(e)}")
                return jsonify({
                    "error": f"Failed to download video: {str(e)}",
                    "status": "error"
                }), 500

        @self.app.route('/test-ken-burns', methods=['POST'])
        def test_ken_burns():
            """Test Ken Burns effect on a single video"""
            try:
                from flask import request

                self.logger.info("üé¨ Testing Ken Burns effect on a video")

                # Get parameters from request
                data = request.get_json() or {}
                article_id = data.get('article_id')

                # If no article_id provided, get the latest article with audio
                if not article_id:
                    latest_article = self.news_collection.find_one(
                        {
                            'audio_paths': {'$ne': None, '$exists': True},
                            'image': {'$ne': None, '$exists': True},
                            'status': {'$in': ['completed', 'published']}
                        },
                        sort=[('created_at', -1)]
                    )

                    if not latest_article:
                        return jsonify({
                            "error": "No articles with audio found",
                            "status": "error"
                        }), 404

                    article_id = latest_article['id']
                else:
                    latest_article = self.news_collection.find_one({'id': article_id})

                    if not latest_article:
                        return jsonify({
                            "error": f"Article {article_id} not found",
                            "status": "error"
                        }), 404

                self.logger.info(f"üìä Testing Ken Burns effect on article: {article_id}")

                # Generate video with Ken Burns effect
                result = self.video_service.generate_video_for_article(latest_article)

                if result['status'] == 'success':
                    # Update database with video path
                    self.news_collection.update_one(
                        {'id': article_id},
                        {'$set': {
                            'video_path': result['video_path'],
                            'updated_at': datetime.utcnow()
                        }}
                    )

                    return jsonify({
                        "message": "Ken Burns effect test completed successfully",
                        "status": "success",
                        "article_id": article_id,
                        "video_path": result['video_path'],
                        "download_url": f"/download/{os.path.basename(result['video_path'])}",
                        "ken_burns_config": {
                            "enabled": self.config.ENABLE_KEN_BURNS,
                            "zoom_start": self.config.KEN_BURNS_ZOOM_START,
                            "zoom_end": self.config.KEN_BURNS_ZOOM_END,
                            "easing": self.config.KEN_BURNS_EASING
                        }
                    })
                else:
                    return jsonify({
                        "error": result.get('error', 'Unknown error'),
                        "status": "error",
                        "article_id": article_id
                    }), 500

            except Exception as e:
                self.logger.error(f"‚ùå Error testing Ken Burns effect: {str(e)}")
                return jsonify({
                    "error": f"Failed to test Ken Burns effect: {str(e)}",
                    "status": "error"
                }), 500


if __name__ == '__main__':
    # Create and run the job service
    job = VideoGeneratorJob()

    # Start the Flask application with job scheduling
    job.run_flask_app()

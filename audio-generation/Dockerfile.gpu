# GPU-enabled Dockerfile for Audio Generation Factory
# Using devel image instead of runtime for full CUDA support
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

# Set timezone non-interactively
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Set working directory
WORKDIR /app

# Install Node.js 18, Python, and system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    ffmpeg \
    git \
    python3 \
    python3-pip \
    python3-venv \
    espeak-ng \
    && curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \
    && apt-get install -y nodejs \
    && rm -rf /var/lib/apt/lists/*

# Create Python virtual environment and install dependencies with CUDA support
RUN python3 -m venv /app/venv

# Install PyTorch with CUDA 11.8 support FIRST
RUN /app/venv/bin/pip install --no-cache-dir --upgrade pip && \
    /app/venv/bin/pip install --no-cache-dir \
    torch==2.1.2+cu118 \
    torchvision==0.16.2+cu118 \
    torchaudio==2.1.2+cu118 \
    --index-url https://download.pytorch.org/whl/cu118

# Install NumPy <2.0 for compatibility
RUN /app/venv/bin/pip install --no-cache-dir "numpy>=1.20.0,<2.0"

# Install other dependencies WITHOUT upgrading torch or numpy
RUN /app/venv/bin/pip install --no-cache-dir --ignore-installed blinker \
    --no-deps \
    kokoro>=0.9.4 \
    soundfile \
    scipy \
    num2words \
    semantic-text-splitter

# Install Bark and its dependencies (transformers, etc.) with compatible versions
RUN /app/venv/bin/pip install --no-cache-dir \
    "transformers>=4.31.0,<4.36.0" \
    "encodec>=0.1.1" \
    "funcy" \
    git+https://github.com/suno-ai/bark.git

# Install spaCy and pydub for V1 text chunker (legacy) and audio merging
# NOTE: V2 chunker (semantic-text-splitter) is recommended - set TEXT_CHUNKER_VERSION=v2
# spaCy is kept for backward compatibility with V1 chunker
RUN /app/venv/bin/pip install --no-cache-dir \
    spacy \
    pydub

# Download spaCy language models (only needed for V1 chunker)
# - en_core_web_sm: English model for accurate sentence detection
# - xx_sent_ud_sm: Multi-language model for Hindi and other languages
RUN /app/venv/bin/python -m spacy download en_core_web_sm && \
    /app/venv/bin/python -m spacy download xx_sent_ud_sm

RUN /app/venv/bin/pip install --no-cache-dir indic-numtowords

# Create data directory for model caching
RUN mkdir -p /app/data/models /app/public && \
    chmod 777 /app/data /app/public

# Copy package files
COPY package*.json ./

# Install Node.js dependencies
# Skip onnxruntime CUDA installation (we use PyTorch for GPU, not ONNX Runtime)
ENV npm_config_onnxruntime_node_install_cuda=skip
RUN npm install

# Copy application code
COPY . .

# Make Python scripts executable
RUN chmod +x /app/utils/text_chunker.py /app/utils/text_chunker_v2.py /app/utils/audio_merger.py

# Set environment variables for GPU
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTORCH_ALLOC_CONF=max_split_size_mb:512

# Set Bark model cache directory to persistent storage
ENV XDG_CACHE_HOME=/app/data/cache
ENV SUNO_USE_SMALL_MODELS=False
ENV SUNO_OFFLOAD_CPU=False

# Coqui TTS server URL (will connect to separate Coqui TTS container)
ENV COQUI_TTS_URL=http://coqui-tts:5002

# Create volume mount point for persistent model storage
VOLUME ["/app/data"]

# Expose port
EXPOSE 3000

# Start the application
CMD ["node", "server.js"]

